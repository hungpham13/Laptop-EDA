{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import csv\n",
    "    from bs4 import BeautifulSoup\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    import selenium.webdriver.support.expected_conditions as EC\n",
    "    from selenium.webdriver.common.by import By\n",
    "\n",
    "    driver = webdriver.Chrome('/home/hung/Downloads/chromedriver')\n",
    "    url = \"https://www.thegioididong.com/laptop#pi=8\"\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    result = soup.find_all('li',{'class':'item ajaxed __cate_44'})\n",
    "    scraped = 0\n",
    "    for item in result:\n",
    "        url0 = 'https://www.thegioididong.com' + item.a.get('href') + '#top-tskt'\n",
    "        driver.get(url0)\n",
    "        btn = driver.find_element(By.CSS_SELECTOR,'.btn-detail.btn-short-spec').click()\n",
    "        WebDriverWait(driver,timeout=5).until(EC.visibility_of_element_located((By.CSS_SELECTOR,'.parameter-all')))\n",
    "        soup0 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        all =  soup0.find('div',{'class':'content-t-wrap'}).find_all('li')\n",
    "        if len(all) >= 30:\n",
    "            print(len(all))\n",
    "        scraped += 1\n",
    "        print(scraped)\n",
    "    print(len(result),\"scrapped:\",scraped)\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-8dd47fe60a14>:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/home/hung/Downloads/chromedriver')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome('/home/hung/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.thegioididong.com/laptop#pi=8\"\n",
    "\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "result = soup.find_all('li',{'class':'item ajaxed __cate_44'})\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acer Nitro 5 Gaming AN515 57 727J i7 11800H (NH.QD9SV.005.)\n"
     ]
    }
   ],
   "source": [
    "item = result[0]\n",
    "title = item.a.h3.text.strip()\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-3d7a30b75a15>:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_css_selector('.btn-detail.btn-short-spec').click()\n"
     ]
    }
   ],
   "source": [
    "url0 = 'https://www.thegioididong.com' + item.a.get('href')\n",
    "driver.get(url0)\n",
    "driver.find_element_by_css_selector('.btn-detail.btn-short-spec').click()\n",
    "soup0 = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_id_to_name = {\n",
    "    '28727':'cpu_name',\n",
    "    '28859':'cpu_ncores',\n",
    "    '28860':'cpu_nthreads',\n",
    "    '93':'cpu_basefreq',\n",
    "    '97':'cpu_turbofreq',\n",
    "    '28861':'cpu_cache',\n",
    "    \n",
    "    '146':'ram_size',\n",
    "    '149':'ram_type',\n",
    "    '155':'ram_clock',\n",
    "    '137':'ram_upgradable',\n",
    "    \n",
    "    '184':'storage',\n",
    "    '28123':'gpu',\n",
    "    '228':'battery',\n",
    "    \n",
    "    '187':'displ_size',\n",
    "    '189':'displ_resolution',\n",
    "    '29056':'displ_rate',\n",
    "    '186':'displ_tech',\n",
    "    '480':'displ_touchscreen',\n",
    "\n",
    "    '196':'sound',\n",
    "    '200':'ports',\n",
    "    '218':'sd_card',\n",
    "    '206':'wless_connect',\n",
    "    '223':'webcam',\n",
    "    '201':'special',\n",
    "    '10741':'backlight_key',\n",
    "\n",
    "    '7779':'weight_dims',\n",
    "    '7903':'surface',\n",
    "    '8599':'os',\n",
    "    '22711':'launch'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_scrap(data_id,soup0):\n",
    "    '''data_id: str'''\n",
    "    li = soup0.find('li',{'data-id':data_id})\n",
    "    if not li:\n",
    "        return ''\n",
    "    ls = []\n",
    "    for p in li.find_all('p',{'class':'circle'}):\n",
    "        if p.text: ls.append(p.text.strip())\n",
    "        else: ls.append(p.a.text.strip())\n",
    "    os = \"|\".join(ls)\n",
    "    if not os:\n",
    "        try:\n",
    "            os = li.span.text.strip()\n",
    "        except:\n",
    "            os = '|'.join(a.text.strip() for a in li.find_all('a'))\n",
    "    return os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 bình luận\n"
     ]
    }
   ],
   "source": [
    "title = soup0.find('h1').text.strip()\n",
    "price = soup0.find('p',{'class':'box-price-present'}).text.strip()\n",
    "rating = soup0.find('p',{'class':'point'}).text.strip()\n",
    "review_count = soup0.find('a',{'class':'rating-total'}).text.strip()\n",
    "cmt_count = soup0.find('span',{'class':'totalcomment'}).text[:22].strip()\n",
    "print(cmt_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 scrapped: 1\n",
      "171 scrapped: 2\n",
      "171 scrapped: 3\n",
      "171 scrapped: 4\n",
      "171 scrapped: 5\n",
      "171 scrapped: 6\n",
      "171 scrapped: 7\n",
      "171 scrapped: 8\n",
      "171 scrapped: 9\n",
      "171 scrapped: 10\n",
      "171 scrapped: 11\n",
      "171 scrapped: 12\n",
      "171 scrapped: 13\n",
      "171 scrapped: 14\n",
      "171 scrapped: 15\n",
      "171 scrapped: 16\n",
      "171 scrapped: 17\n",
      "171 scrapped: 18\n",
      "171 scrapped: 19\n",
      "171 scrapped: 20\n",
      "171 scrapped: 21\n",
      "171 scrapped: 22\n",
      "171 scrapped: 23\n",
      "171 scrapped: 24\n",
      "171 scrapped: 25\n",
      "171 scrapped: 26\n",
      "171 scrapped: 27\n",
      "171 scrapped: 28\n",
      "171 scrapped: 29\n",
      "171 scrapped: 30\n",
      "171 scrapped: 31\n",
      "171 scrapped: 32\n",
      "171 scrapped: 33\n",
      "171 scrapped: 34\n",
      "171 scrapped: 35\n",
      "171 scrapped: 36\n",
      "171 scrapped: 37\n",
      "171 scrapped: 38\n",
      "171 scrapped: 39\n",
      "171 scrapped: 40\n",
      "171 scrapped: 41\n",
      "171 scrapped: 42\n",
      "171 scrapped: 43\n",
      "171 scrapped: 44\n"
     ]
    }
   ],
   "source": [
    "headers = ['title','price','rating','review_count','cmt_count'] + list(spec_id_to_name.values())\n",
    "result = pd.DataFrame(columns = headers)\n",
    "scraped = 0 #track the number of scraped laptop\n",
    "\n",
    "url = \"https://www.thegioididong.com/laptop#pi=10\"\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "laptops = soup.find_all('li',{'class':'item ajaxed __cate_44'})\n",
    "\n",
    "#for each row\n",
    "for item in laptops:\n",
    "    url0 = 'https://www.thegioididong.com' + item.a.get('href') + '#top-tskt'\n",
    "    driver.get(url0)\n",
    "    soup0 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    #start scraping title, price, rating, review_count, cmt_count\n",
    "    title = soup0.find('h1').text.strip()\n",
    "    try: price = soup0.find('p',{'class':'box-price-present'}).text.strip()\n",
    "    except: price = ''\n",
    "    try: rating = soup0.find('p',{'class':'point'}).text.strip()\n",
    "    except: rating = ''\n",
    "    try: review_count = soup0.find('a',{'class':'rating-total'}).text.strip()\n",
    "    except: review_count = ''\n",
    "    try: cmt_count = soup0.find('span',{'class':'totalcomment'}).text[:22].strip()\n",
    "    except: cmt_count=''\n",
    "\n",
    "    #click the button\n",
    "    btn = driver.find_element(By.CSS_SELECTOR,'.btn-detail.btn-short-spec').click()\n",
    "    WebDriverWait(driver,timeout=5).until(EC.visibility_of_element_located((By.CSS_SELECTOR,'.parameter-all')))\n",
    "    \n",
    "    #start scraping specs\n",
    "    soup0 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    specs_row = [spec_scrap(id,soup0) for id in spec_id_to_name]\n",
    "    \n",
    "    #saved the result\n",
    "    result.loc[len(result.index)] = [title,price,rating,review_count,cmt_count] + specs_row\n",
    "    scraped += 1\n",
    "    print(len(laptops),\"scrapped:\",scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 34)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('thegioididong.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
