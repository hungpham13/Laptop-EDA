{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T00:03:37.419265Z",
     "start_time": "2021-10-31T00:03:37.413023Z"
    }
   },
   "source": [
    "# Scrap CellphoneS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T14:40:35.265059Z",
     "start_time": "2021-11-07T14:40:32.160209Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:55:31.112284Z",
     "start_time": "2021-10-30T01:55:31.107096Z"
    }
   },
   "outputs": [],
   "source": [
    "# # this notebook was originally run on linux using Google Chrome\n",
    "\n",
    "# !sudo cp ./chromedriver /usr/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T16:58:55.619254Z",
     "start_time": "2021-11-07T16:58:55.591006Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_details(url):\n",
    "    \"\"\"Extract the details of an item.\n",
    "    \n",
    "    Argument:\n",
    "        url -- url to the item's page.\n",
    "        \n",
    "    Return:\n",
    "        a dictionary containing all details scrapped for the specified item.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {}\n",
    "        \n",
    "    driver.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    data['url'] = url\n",
    "    \n",
    "    # name\n",
    "    data['item_name'] = soup.find('div', {'class': 'box-name__box-product-name'}).h1.text.strip()\n",
    "\n",
    "    # price\n",
    "    price_box = soup.find('div', 'box-info__box-price')\n",
    "    try:\n",
    "        data['special_price'] = price_box.find('p', {'class': 'special-price'}).text[:-2]\n",
    "    except:\n",
    "        data['special_price'] = None\n",
    "    try:\n",
    "        data['old_price'] = price_box.find('p', {'class': 'old-price'}).text[:-2]\n",
    "    except:\n",
    "        data['old_price'] = None\n",
    "    \n",
    "    # versions with different prices\n",
    "#     versions_raw = soup.find_all('a', 'item-linked')\n",
    "    \n",
    "#     if len(versions_raw) == 1:\n",
    "#         print(url)\n",
    "    \n",
    "#     if len(versions_raw) > 0:\n",
    "#         for version in versions_raw:\n",
    "#             if version.get('href') not in url_list[-len(versions_raw):]:\n",
    "#                 url_list.append(version.get('href'))\n",
    "\n",
    "#     try:\n",
    "#         data['version'] = versions_raw[0].span.text[:-2]\n",
    "#     except:\n",
    "#         data['version'] = None\n",
    "    \n",
    "    # rating\n",
    "    rating_raw = soup.find_all('div', 'item-statistical')\n",
    "    rating = {\n",
    "        (level.find('p', 'number-star').strong.text + 'star'): level.find('p', 'number-percent').text[:-9]\n",
    "        for level in rating_raw\n",
    "    }\n",
    "    data.update(rating)\n",
    "    \n",
    "    # specifications\n",
    "    info_table = soup.find('div', {'id': 'technicalInfoModal'}).find_all('th')\n",
    "\n",
    "    infos = {\n",
    "        info_table[2*i].text: info_table[2*i + 1].text for i in range(len(info_table)//2)\n",
    "    }\n",
    "    data.update(infos)\n",
    "    \n",
    "    # comment count\n",
    "    try:\n",
    "        data['comment_count'] = soup.find('p', {'id': 'total_comment'}).text.split()[3][1:]\n",
    "    except:\n",
    "        data = get_details(url)\n",
    "    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:04:20.998891Z",
     "start_time": "2021-11-07T17:03:42.011825Z"
    }
   },
   "outputs": [],
   "source": [
    "page_url = \"https://cellphones.com.vn/laptop.html\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(page_url)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# click to the \"show more\" button to get full list of laptops\n",
    "load = True\n",
    "while load:\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'btn-show-more'))\n",
    "            ).click()        \n",
    "    except:\n",
    "        load = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:04:24.127755Z",
     "start_time": "2021-11-07T17:04:22.375441Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# scrap the list of laptops\n",
    "results = soup.find_all('div', {\"class\": \"item-product\"})\n",
    "\n",
    "str(len(results)) + ' laptops found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:03:38.213737Z",
     "start_time": "2021-11-07T17:03:38.203700Z"
    }
   },
   "outputs": [],
   "source": [
    "url_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:13:12.884752Z",
     "start_time": "2021-11-07T17:04:39.860993Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# while True:\n",
    "#     if j < len(results):\n",
    "#         url_list.append(results[j].find('a').get('href'))\n",
    "#         j += 1\n",
    "    \n",
    "#     if i < len(url_list):\n",
    "#         record = get_details(url_list[i])\n",
    "#         records.append(record)\n",
    "#         print(record['item_name'])\n",
    "#         i += 1\n",
    "        \n",
    "#     if i > len(url_list):\n",
    "#         break\n",
    "\n",
    "for item in results:\n",
    "    driver.get(item.find('a').get('href'))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    versions_raw = soup.find_all('a', 'item-linked')\n",
    "    \n",
    "    if len(versions_raw) == 1:\n",
    "        print(item.find('a').get('href'))\n",
    "    \n",
    "    if len(versions_raw) > 0:\n",
    "        url_list.extend([version.get('href') for version in versions_raw])\n",
    "    else:\n",
    "        url_list.append(item.find('a').get('href'))\n",
    "        \n",
    "for url in url_list:\n",
    "    record = get_details(url)\n",
    "    records.append(record)\n",
    "    print(record['item_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:13:19.627939Z",
     "start_time": "2021-11-07T17:13:19.606332Z"
    }
   },
   "outputs": [],
   "source": [
    "key_set = set()\n",
    "\n",
    "for record in records:\n",
    "    for k in record.keys():\n",
    "        key_set.add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T17:13:22.484142Z",
     "start_time": "2021-11-07T17:13:22.439156Z"
    }
   },
   "outputs": [],
   "source": [
    "# save records to .csv file\n",
    "file = open('records_cellphones.csv', 'w')\n",
    "writer = csv.DictWriter(file, key_set)\n",
    "writer.writeheader()\n",
    "writer.writerows(records)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
